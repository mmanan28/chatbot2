{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hare Krishna\\Desktop\\LLM\\venv\\Lib\\site-packages\\pinecone\\data\\index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import langchain\n",
    "import pinecone \n",
    "import os\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Pinecone as LangchainPinecone\n",
    "from langchain.llms import OpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from pinecone import Pinecone, PineconeConfigurationError, ServerlessSpec\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_pinecone import Pinecone\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
    "from langchain.chains import RetrievalQA\n",
    "from pinecone import Pinecone as pc\n",
    "from pinecone import Pinecone as PineconeClient\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_doc(directory):\n",
    "    file_loader=PyPDFDirectoryLoader(directory)\n",
    "    documents=file_loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc=read_doc('documents/')\n",
    "len(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_data(docs,chunk_size=800,chunk_overlap=50):\n",
    "    text_splitter=RecursiveCharacterTextSplitter(chunk_size=chunk_size,chunk_overlap=chunk_overlap)\n",
    "    doc=text_splitter.split_documents(docs)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents=chunk_data(docs=doc)\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings=OpenAIEmbeddings(api_key=os.environ['OPENAI_API_KEY'])\n",
    "# embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors=embeddings.embed_query(\"How are you?\")\n",
    "len(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = os.getenv('PINECONE_API_KEY')\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if not PINECONE_API_KEY:\n",
    "    raise ValueError(\"Pinecone API key not found. Please set the PINECONE_API_KEY environment variable.\")\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"OpenAI API key not found. Please set the OPENAI_API_KEY environment variable.\")\n",
    "\n",
    "# Initialize Pinecone with API key\n",
    "\n",
    "#pinecone.init(api_key=PINECONE_API_KEY)\n",
    "\n",
    "try:\n",
    "    pc = PineconeClient(api_key=os.environ.get(\"PINECONE_API_KEY\"))\n",
    "except PineconeConfigurationError as e:\n",
    "    print(f\"Error initializing Pinecone: {e}\")\n",
    "\n",
    "index_name = \"m4\"\n",
    "\n",
    "# Create a Pinecone index if it doesn't exist\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pinecone.create_index(\n",
    "        name=index_name,\n",
    "        dimensions=1536,\n",
    "        metric='cosine',\n",
    "        spec=ServerlessSpec(cloud='aws', region='us-east-1'),\n",
    "        host='https://m4-p23bwks.svc.aped-4627-b74a.pinecone.io'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = LangchainPinecone.from_documents(documents, embeddings, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_query(query,k=2):\n",
    "    matching_results=index.similarity_search(query,k=k)\n",
    "    return matching_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hare Krishna\\Desktop\\LLM\\venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "llm=OpenAI(model_name=\"text-embedding-3-small\",temperature=0.5)\n",
    "chain=load_qa_chain(llm,chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_answers(query):\n",
    "    doc_search=retrieve_query(query)\n",
    "    print(doc_search)\n",
    "    response=chain.run(input_documents=doc_search,question=query)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hare Krishna\\Desktop\\LLM\\venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `Pinecone` was deprecated in LangChain 0.0.18 and will be removed in 0.3.0. An updated version of the class exists in the langchain-pinecone package and should be used instead. To use it run `pip install -U langchain-pinecone` and import as `from langchain_pinecone import Pinecone`.\n",
      "  warn_deprecated(\n",
      "c:\\Users\\Hare Krishna\\Desktop\\LLM\\venv\\Lib\\site-packages\\langchain_community\\vectorstores\\pinecone.py:68: UserWarning: Passing in `embedding` as a Callable is deprecated. Please pass in an Embeddings object instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "text_field = \"text\"  # the metadata field that contains our text\n",
    "\n",
    "# initialize the vector store object\n",
    "vectorstore = Pinecone(\n",
    "    pc.Index(\"m4\"), embeddings.embed_query, text_field\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "greetings = [\"hi\", \"helo\", \"hello\", \"hey\", \"good morning\", \"good evening\",\"good evening\",\"anyone here\",   'howdy','salutations','hiya','hey there','good day',\"what's up\",'how are you','yo','hi there',\"how's it going\",\"how's everything\",\"how's life\",'nice to see you','pleased to meet you','good to see you','welcome','hi ya','hello there','how have you been',\"what's going on\",'how are things','how do you do',\"what's happening\",\"how's your day\",\"how's your day going\",\"what's new\",\"what's good\",\"how's it hanging\",'how are things going',\"how's your morning\",\"how's your afternoon\",\"how's your evening\",'what have you been up to',\n",
    "    'long time no see',\"it's been a while\",'how have you been lately',\"how's everything going\",\"how's it been\",\"how's your week\",\"what's the latest\",\"how's your weekend\",'what have you been doing',\"what's been happening\",'yes','no','sure','yeah','nope','yep','nah','okay','alright','absolutely','of course','definitely','affirmative','negative','indeed','certainly','sure thing','yup','uh huh','no way','not at all','by all means','no thanks','roger','right','fine','okay dokey','okie dokie','for sure','no problem','you bet','absolutely not','no doubt','unquestionably','without a doubt','no chance','yes please','not really','totally',\"I'm in\",'I agree',\"I'm on board\",'that works',\"I'll pass\",'not interested','why not','sure thing','count me in','you got it']\n",
    "reply= [\n",
    "    \"\"\"Welcome to Iotric, what will you like to opt for.\n",
    "    1. Explore our services.\n",
    "    2. Explore our Portfolio.\n",
    "    3. Iotric Products.\n",
    "    4. Iotric Blogs.\n",
    "    5. Contact us.\n",
    "    6. Schedule a meeting.\"\"\"\n",
    "]\n",
    "\n",
    "blog_keywords = [\"blog\", \"blogs\", \"articles\", \"iotric blogs\", \"read\", \"latest blog\", \"read blog\",\n",
    "    \"blog posts\", \"recent blogs\", \"recent articles\", \"write-ups\", \"latest articles\",\n",
    "    \"blog section\", \"blog page\", \"blog content\", \"published articles\", \"featured blog\",\n",
    "    \"latest write-ups\", \"blog updates\", \"new blogs\", \"new articles\", \"recent posts\",\n",
    "    \"insights\", \"company blog\", \"industry articles\", \"tech blogs\", \"technology articles\",\n",
    "    \"trending blogs\", \"trending articles\", \"expert insights\", \"thought leadership\",\n",
    "    \"blogging\", \"blogging platform\", \"blog collections\", \"content hub\", \"knowledge base\",\n",
    "    \"online articles\", \"digital articles\", \"company write-ups\", \"company insights\"]\n",
    "blog_reply = [\n",
    "    \"Here are some of our latest blogs:\",\n",
    "    \"1. How to use MVP development to mitigate risk?: https://www.iotric.com/mvp-development-to-mitigate-risk/\",\n",
    "    \"2. Minimum Viable Product (MVP) vs Minimum Marketable Product (MMP): https://www.iotric.com/mvp-vs-mmp/\",\n",
    "    \"3. What is Fractional Ownership in Real Estate Investment with Blockchain?: https://www.iotric.com/what-is-fractional-ownership-in-real-estate-investment-with-blockchain/\",\n",
    "    \"Visit our blog page https://www.iotric.com/blog/ for more articles!\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_greeting_reply(user_input):\n",
    "    user_input = user_input.lower()\n",
    "    if user_input in greetings:\n",
    "        return reply\n",
    "    \n",
    "    if any(keyword in user_input for keyword in blog_keywords):\n",
    "        return blog_reply\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'page': 16.0, 'source': 'documents\\\\iotric knowledge base 3.pdf'}, page_content='Byee!  \\nGoodbye! If you have any more questions in the future, feel free to ask. Have a \\ngreat day! \\n \\nThank You! \\nYouâ€™re Welcome! Feel free to ask again. \\n \\n \\n \\n ')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''query = \"hello\"\n",
    "\n",
    "vectorstore.similarity_search(\n",
    "    query,  # our search query\n",
    "    k= 1 # return 3 most relevant docs\n",
    ")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hare Krishna\\Desktop\\LLM\\venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# chat completion llm\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "    model_name='gpt-3.5-turbo',\n",
    "    temperature=0.0\n",
    ")\n",
    "# conversational memory\n",
    "conversational_memory = ConversationBufferWindowMemory(\n",
    "    memory_key='chat_history',\n",
    "    k=1,\n",
    "    return_messages=True\n",
    ")\n",
    "# retrieval qa chain\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstore.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some of our latest blogs:\n",
      "1. How to use MVP development to mitigate risk?: https://www.iotric.com/mvp-development-to-mitigate-risk/\n",
      "2. Minimum Viable Product (MVP) vs Minimum Marketable Product (MMP): https://www.iotric.com/mvp-vs-mmp/\n",
      "3. What is Fractional Ownership in Real Estate Investment with Blockchain?: https://www.iotric.com/what-is-fractional-ownership-in-real-estate-investment-with-blockchain/\n",
      "Visit our blog page https://www.iotric.com/blog/ for more articles!\n"
     ]
    }
   ],
   "source": [
    "query = \"blogs\"\n",
    "\n",
    "# Check for greeting or blog reply\n",
    "reply = get_greeting_reply(query)\n",
    "\n",
    "if reply:\n",
    "    print(\"\\n\".join(reply))  # Joins and prints the reply lines\n",
    "else:\n",
    "    # If not a greeting or blog query, perform the retrieval-based QA\n",
    "    modified_query = query + \" in points\"\n",
    "    response = qa.invoke(modified_query)\n",
    "    if 'result' in response:\n",
    "        print(response['result'])\n",
    "    else:\n",
    "        print(response)\n",
    "        print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'hello', 'result': 'Hello! Welcome to Iotric. How can I assist you today?'}\n"
     ]
    }
   ],
   "source": [
    "'''a = qa.invoke(query)\n",
    "print(a)'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
